# 线性回归 与 逻辑回归

# 决策树
- 特征选择
- 决策树生成
- 决策树剪枝
# SVM
## 工作原理
支持向量机是一种二类分类模型，属于有监督学习的一种。其基本模型定义为特征空间上的间隔最大的线性分类器，学习策略是间隔最大化，最终可转化为一个凸二次规划问题的求解。
在样本空间中，距离超平面最近的这几个训练样本点被称为“支持向量”（support vector）
- 训练样本线性可分：硬间隔最大化
- 近似线性可分：引入松弛变量，通过软间隔最大化
- 线性不可分：核函数以及软间隔最大化，学习非线性分类器

## 优点
- 可以解决高维问题，即大型特征空间；
- 小样本下机器学习问题：SVM在小样本数据集上表现良好，因为它可以利用核函数将少量的数据点映射到高维空间中，从而提高分类的准确性。
- 通过核函数引入引入非线性：高维空间中，几乎所有的分类问题都是线性可分的
- 泛化能力比较强：最终决策函数只由少数的支持向量所确定，避免维数灾难
## 缺点：
- 计算复杂度高：大规模训练数据难以实施
- 缺失数据、参数和核函数选择敏感，而且没有完全解决非线性
- 多分类问题困难

# 贝叶斯

# KNN

# 随机森林

# 神经网络
